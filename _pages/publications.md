---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

\* indicates equal contribution

<b>[Understanding Representation Dynamics of Diffusion Models via Low-Dimensional Modeling](https://arxiv.org/abs/2502.05743)</b><br>
<b>Xiao Li\*</b>, Zekai Zhang\*, Xiang Li, Siyi Chen, Zhihui Zhu, Peng Wang, Qing Qu. Preprint 2025.

<b>[Understanding Deep Representation Learning via Layerwise Feature Compression and Discrimination](https://arxiv.org/abs/2311.02960)</b><br>
Peng Wang\*, <b>Xiao Li\*</b>, Can Yaras, Zhihui Zhu, Laura Balzano, Wei Hu, Qing Qu.
<i>Journal of Machine Learning Research</i>. <b>JMLR 2025</b>.

<b>[Neural Collapse in Multi-label Learning with Pick-all-label Loss](https://arxiv.org/abs/2310.15903)</b><br>
Pengyu Li\*, <b>Xiao Li\*</b>, Yutong Wang, Qing Qu.
<i>The 41th International Conference on Machine Learning</i>. <b>ICML 2024</b>.

<b>[Investigating the Catastrophic Forgetting in Multimodal Large Language Models](https://arxiv.org/abs/2309.10313)</b><br>
Yuexiang Zhai, Shengbang Tong, <b>Xiao Li</b>, Mu Cai, Qing Qu, Yong Jae Lee, Yi Ma.
<i>Conference on Parsimony and Learning</i>. <b>CPAL 2024</b>.
  
<b>[Understanding and Improving Transfer Learning of Deep Models via Neural Collapse](https://arxiv.org/abs/2212.12206)</b><br>
<b>Xiao Li\*</b>, Sheng Liu\*, Jinxin Zhou, Xinyu Lu, Carlos Fernandez-Granda, Zhihui Zhu, Qing Qu. 
<i>Transactions on Machine Learning Research</i>. <b>TMLR 2024</b>.

<b>[Dynamic Low-rank Estimation for Transformer-based Language Models](https://aclanthology.org/2023.findings-emnlp.621.pdf)</b><br>
Ting Hua\*, <b>Xiao Li\*</b>, Shangqian Gao, Yen-Chang Hsu, Yilin Shen, Hongxia Jin.
<i>The 2023 Conference on Empirical Methods in Natural Language Processing</i>. <b>EMNLP 2023 Findings</b>.

<b>[Are All Losses Created Equal: A Neural Collapse Perspective](https://arxiv.org/abs/2210.02192)</b><br>
Jinxin Zhou, Chong You, <b>Xiao Li</b>, Kangning Liu, Sheng Liu, Qing Qu, Zhihui Zhu.
<i>The 35th Conference on Neural Information Processing Systems</i>. <b>NeurIPS 2022</b>.

<b>[On the Optimization Landscape of Neural Collapse under MSE Loss: Global Optimality with Unconstrained Features](https://arxiv.org/abs/2203.01238)</b><br>
Jinxin Zhou\*, <b>Xiao Li\*</b>, Tianyu Ding, Chong You, Qing Qu, Zhihui Zhu.
<i>The 39th International Conference on Machine Learning</i>. <b>ICML 2022</b>.

<b>[Deep-SMOLM: deep learning resolves the 3D orientations and 2D positions of overlapping single molecules with optimal nanoscale resolution](https://opg.optica.org/oe/fulltext.cfm?uri=oe-30-20-36761&id=505938)</b><br>
Tingting Wu, Peng Lu, Md Ashequr Rahman, <b>Xiao Li</b>, Matthew D Lew.
<i>Optics Express 30 (20), 36761-36773</i>. <b>Optics Expres 2022</b>.

<b>[A Geometric Analysis of Neural Collapse with Unconstrained Features](https://arxiv.org/abs/2105.02375)</b><br>
Zhihui Zhu\*, Tianyu Ding\*, Jinxin Zhou, <b>Xiao Li</b>, Chong You, Jeremias Sulam, Qing Qu.
<i>The 35th Conference on Neural Information Processing Systems</i>. <b>NeurIPS 2021</b>.

<b>[Convolutional normalization: Improving deep convolutional network robustness and training](https://arxiv.org/abs/2103.00673)</b><br>
Sheng Liu\*, <b>Xiao Li\*</b>, Yuexiang Zhai, Chong You, Zhihui Zhu, Carlos Fernandez-Granda, Qing Qu.
<i>The 35th Conference on Neural Information Processing Systems</i>. <b>NeurIPS 2021</b>.
